<html lang="en">
    <head>
        <!-- Change title from here -->
        <title>CoT3DRef</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous" />
        <link rel="stylesheet" type="text/css" href="benchmarking.css" />
    </head>

    <body data-new-gr-c-s-check-loaded="14.1100.0" data-gr-ext-installed="" cz-shortcut-listen="true">
        <div class="container-fluid">
            <!-- This is the navigation bar on the top -->
            <nav class="navbar navbar-expand-sm navbar-light bg-faded">
                <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#nav-content" aria-controls="nav-content" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Here is the first image and the link it goes to -->
                <a class="nav-link active" href="#"><img src="./static/images/COT3DRef_logo.png" width="100" /></a>
                <div class="collapse navbar-collapse" id="nav-content">
                    <ul class="navbar-nav">
                        <li class="nav-item">
                            <!-- Here is the second image and the link it goes to -->
                            <!-- <a class="nav-link active" href="#"><img src="./static/images/COT3DRef_logo.png" width="80" /></a> -->
                        </li>
                        <!-- These are the items on the right -->
                        <li class="nav-item"><a class="nav-link active" href="quantitaive_results.html">Quantitaive Results</a></li>
                        <li class="nav-item"><a class="nav-link active" href="qualitative_results.html">Qualitative Results</a></li>

                    </ul>
                </div>

                <div class="text-right" id="summary" style="white-space: nowrap;">
                    
                </div>
            </nav>
            <div class="row">
                <div class="col-sm-12" id="main">
                    <div class="row">
                        <div class="col-sm-12">
                            <a href=""><img src="./static/images/COT3DRef_logo.png" class="mx-auto d-block" style="width: 500px;" /></a>
                        </div>
                        <div class="col-sm-12">
                            <div class="text-center">
                                <!-- <a href="https://drive.google.com/drive/folders/1AlA259sXi-3ZJD7RFaL2bGDwJXLImJrx?usp=share_link" class="main-link btn btn-lg m-5 px-5">Data</a> -->
                                <a href="#" class="main-link btn btn-lg m-5 px-5">Paper</a>
                                <a href="https://github.com/CoT3DRef/COT3DRef" class="main-link btn btn-lg m-5 px-5">GitHub</a>
                            </div>
                        </div>
                        <div class="col-sm-2"></div>
                        <div class="col-sm-8">
                            
                            <h2>CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding</h2>
                            <div class="text-center"><img src="./static/images/CoT_teaser_figure-1.png" style="width: 700px;margin-bottom:50px;margin-top:10px;" /></div>
                            <p>We aim to address the question of whether an interpretable 3D visual grounding framework, capable of emulating the human perception system, can be designed as shown in the figure above.</p>
                            <h3>How Does CoT3DRef work?</h3>
                                <div class="text-center"><img src="./static/images/CoT_arch-1.png" style="width: 700px;margin-bottom:50px;margin-top:10px;" /></div>

                                <p>To achieve this objective, we formulate the 3D visual grounding problem as a sequence-to-sequence (Seq2Seq) task. As illustrated in the architecture above, the input sequence comprises 3D objects from the scene and an utterance describing a specific object. In contrast to existing architectures, our model predicts both the target object and a chain of anchors on the output side.</p>
                            <h3>Data Data-Efficiency</h3>
                            <!-- <h3 style= "background-color:rgb(237, 234, 240) ; width:100%; margin-top: 50px">Data-Efficiency:</h3> -->
                            <!--Adding a picture of the results-->
                            <div class="text-center"><img src="./static/images/data_eff_2x.png" style="width: 700px;margin-bottom:50px;margin-top:10px;" /></div>
                            <p>We evaluate our framework's effectiveness in a challenging scenario with limited training data. We test our model on four different percentages of data: 10%, 40%, 70%, and 100%. The figure above demonstrates that on the Sr3D dataset, even with only 10% of the data, our model achieves performance comparable to MVT and SAT models trained on 100% of the data. This result highlights the remarkable data efficiency of our model.</p>
                            <!-- <ol>
                                <li>
                                    <b>Holistic skills evaluation</b>. Rather than focus on isolated metrics such as accuracy, we measure 13 skills, which could be categorized into five critical skills; accuracy, robustness, generalization, fairness, and bias.
                                    <div class="text-center"><img src="./static/images/skills_metric.png" style="width: 700px;margin-bottom:50px;margin-top:10px;" /></div>
                                </li>
                                <li>
                                    <b>Broad scenarios coverage</b>. 
                                    HRS-Bench covers 50 applications, e.g., fashion, animals, transportation, food, and clothes.
                                    <div class="text-center"><img src="./static/images/pie_chart.png" style="width: 600px;margin-bottom:50px;margin-top:10px;" /></div>
                                </li>
                                <li>
                                    <b>Standardization</b>. 
                                    We propose a unified benchmark, where we fairly evaluate the existing models across a wide range of metrics.
                                    <div class="text-center"><img src="./static/images/AC_metric.png" style="width: 800px;margin-bottom:50px;margin-top:10px;" /></div>
                                </li>
                            </ol> -->
                        </div>
                        <div class="col-sm-2"></div>
                        <div class="col-sm-2"></div>
                        
                        <h3>Citation: </h3>
                        <p></p>
        <script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.29.0/js/jquery.tablesorter.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/js-yaml/4.1.0/js-yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/showdown/2.0.3/showdown.min.js"></script>
    </body>
    <grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration>
</html>
